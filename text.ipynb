import numpy as np
import tensorflow as tf
from tensorflow.keras.datasets import imdb
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import GridSearchCV
from tensorflow.keras.callbacks import ReduceLROnPlateau
import matplotlib.pyplot as plt

# Load IMDb dataset
num_words = 10000
max_len = 200
(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=num_words)

# Preprocess the data
x_train = pad_sequences(x_train, maxlen=max_len)
x_test = pad_sequences(x_test, maxlen=max_len)

# Define the RNN model
def create_rnn_model(learning_rate=0.001):
    model = Sequential([
        Embedding(input_dim=num_words, output_dim=128, input_length=max_len),
        LSTM(128),
        Dense(1, activation='sigmoid')
    ])
    optimizer = Adam(learning_rate=learning_rate)
    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])
    return model

# Grid search for hyperparameters
param_grid = {
    'learning_rate': [0.001, 0.01, 0.1],
    'batch_size': [32, 64, 128],
    'epochs': [5, 10, 15]
}
rnn_model = tf.keras.wrappers.scikit_learn.KerasClassifier(create_rnn_model)
grid_search = GridSearchCV(estimator=rnn_model, param_grid=param_grid, cv=3, scoring='accuracy')
grid_result = grid_search.fit(x_train, y_train)

# Print best parameters
print("Best parameters found: ", grid_result.best_params_)

# Train the model with best parameters
best_model = create_rnn_model(learning_rate=grid_result.best_params_['learning_rate'])
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.0001)
history = best_model.fit(x_train, y_train, validation_data=(x_test, y_test), 
                         batch_size=grid_result.best_params_['batch_size'], 
                         epochs=grid_result.best_params_['epochs'], 
                         callbacks=[reduce_lr])

# Evaluate the model
test_loss, test_acc = best_model.evaluate(x_test, y_test)
print("Test accuracy:", test_acc)

# Visualize training history
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0, 1])
plt.legend(loc='lower right')
plt.show()
